{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 도서 : [tensorflow 2 로 자연처리]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "Tensorflow \n",
    "drop out\n",
    "Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m📌 - PROGRAM START \n",
      "\t\u001b[0m\n",
      "\u001b[93m📌 - MPS 장치를 지원 Build 여부 : \u001b[0m True\n",
      "\u001b[93m📌 - MPS 장치 사용가능 여부 : \u001b[0m True\n",
      "\u001b[93m📌 - GPU 사용Start\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Forrest Park's notion  ## Updated 2024.07.03\n",
    "### Service  Text Coloring option\n",
    "from Functions import Service as S\n",
    "def blue(str):return S.colored_text(str,'blue')\n",
    "def yellow(str):return S.colored_text(str,'yellow')\n",
    "def red(str):return S.colored_text(str,'red')\n",
    "def green(str):return S.colored_text(str,'green')\n",
    "def imd(str):return S.imd(green(str))\n",
    "## 자연어처리 패키지 설치 \n",
    "def NLPInstalls():\n",
    "    import subprocess,sys\n",
    "    import warnings ; warnings.filterwarnings('ignore')\n",
    "    # pip가 없으면 pip를 설치\n",
    "    try:import pip\n",
    "    except ImportError:\n",
    "        print(\"Install pip for python3\")\n",
    "        subprocess.call(['sudo', 'apt-get', 'install', 'python3-pip'])\n",
    "    \n",
    "    # tweepy 없으면 tweepy 설치\n",
    "    try:import tweepy        \n",
    "    except ModuleNotFoundError:\n",
    "        print(\"Install tweepy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'tweepy==3.10.0'])\n",
    "    finally:import tweepy \n",
    "    \n",
    "    # konlpy 없으면 konlpy 설치\n",
    "    try:import konlpy\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install konlpy\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'konlpy'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # eunjeon 없으면 eunjeon 설치\n",
    "    try:import eunjeon\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install eunjeon : eunjeon\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'eunjeon'])\n",
    "    finally:import konlpy\n",
    "    \n",
    "    # datasets 없으면 datasets를 설치\n",
    "    try:import datasets\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install datasets : datasets\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'datasets'])\n",
    "    finally:import datasets\n",
    "    \n",
    "    # pytorch 없으면 pytorch 설치\n",
    "    try:import torch\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install torch : pytorch\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'pytorch'])\n",
    "    finally:import torch\n",
    "    \n",
    "    # transformers 없으면 transformers 설치\n",
    "    try:import transformers\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install transformer : transformers\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'transformers'])\n",
    "    finally:import transformers\n",
    "        \n",
    "    # UMAP 없으면 UMAP 설치\n",
    "    try:import umap\n",
    "    except ModuleNotFoundError: \n",
    "        print(\"Install umap : umap\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'umap'])\n",
    "    finally:import umap\n",
    "        \n",
    "    # UMAP 없으면 UMAP 설치\n",
    "    try:from umap import UMAP\n",
    "    except ImportError: \n",
    "        print(\"Install umap : umap-learn\")\n",
    "        subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", 'umap-learn'])\n",
    "    finally:import umap\n",
    "   \n",
    "# NLPInstalls()\n",
    "print(yellow(f\"📌 - PROGRAM START \\n\\t\"))\n",
    "## GPU setting (in MacOS)\n",
    "import torch\n",
    "print(yellow(f\"📌 - MPS 장치를 지원 Build 여부 : \"),torch.backends.mps.is_built())\n",
    "print(yellow(f\"📌 - MPS 장치 사용가능 여부 : \"),torch.backends.mps.is_available())\n",
    "print(yellow(f\"📌 - GPU 사용Start\"))\n",
    "# device = torch.device(\"mps\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#### Jupyter Basic Setting ####\n",
    "import pandas as pd,numpy as np\n",
    "import matplotlib.pyplot as plt,seaborn as sns  # 시각화\n",
    "import warnings; warnings.filterwarnings('ignore')  # 경고 무시\n",
    "import sys,os \n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Tensor flow 간단한 자연어 처리 예시 01 page 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m📌 - text =>sequences\u001b[0m\n",
      "[' 너 오늘 이뻐 보인다 => [4, 1, 5, 6]',\n",
      " '나는 오늘 기분이 더러워  => [7, 1, 8, 9]',\n",
      " '끝내주는데, 좋은 일이 있나봐 => [10, 2, 3, 11]',\n",
      " '나 좋은 일이 생겼어 => [12, 2, 3, 13]',\n",
      " '아 오늘 진짜 짜증나 => [14, 1, 15, 16]',\n",
      " '환상적인데, 정말 좋은 거 같아  => [17, 18, 2, 19, 20]']\n",
      "\u001b[93m\n",
      "📌 - word index\u001b[0m\n",
      "{'같아': 20,\n",
      " '거': 19,\n",
      " '기분이': 8,\n",
      " '끝내주는데': 10,\n",
      " '나': 12,\n",
      " '나는': 7,\n",
      " '너': 4,\n",
      " '더러워': 9,\n",
      " '보인다': 6,\n",
      " '생겼어': 13,\n",
      " '아': 14,\n",
      " '오늘': 1,\n",
      " '이뻐': 5,\n",
      " '일이': 3,\n",
      " '있나봐': 11,\n",
      " '정말': 18,\n",
      " '좋은': 2,\n",
      " '진짜': 15,\n",
      " '짜증나': 16,\n",
      " '환상적인데': 17}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing \n",
    "\n",
    "\n",
    "samples = [' 너 오늘 이뻐 보인다',\n",
    "           '나는 오늘 기분이 더러워 ',\n",
    "           '끝내주는데, 좋은 일이 있나봐',\n",
    "           '나 좋은 일이 생겼어',\n",
    "           '아 오늘 진짜 짜증나',\n",
    "           '환상적인데, 정말 좋은 거 같아 ',\n",
    "           ]\n",
    "## labeling \n",
    "labels = [[1],[0],[1],[1],[0],[1]]\n",
    "## tokenize\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "print(yellow(f\"📌 - text =>sequences\"))\n",
    "pprint([(f\"{i} => {j}\") for i,j in zip(samples,sequences)])\n",
    "word_index = tokenizer.word_index\n",
    "print(yellow(f\"\\n📌 - word index\"))\n",
    "pprint(word_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 추가로 모델 구축 및 모델 학습에 피요한 변수 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 6\n",
    "vocab_size =len(word_index) +1\n",
    "emb_size = 128\n",
    "hidden_dimension = 256\n",
    "output_dimension = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 데이터를 통과 시킬 모델 구현\n",
    "- 입력값을 임베딩하는 embedding 층 \n",
    "- 임베딩된 각 단어의 벡터를 평균하기 위해 람다 층을 사용\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size,emb_size,input_length= 4))\n",
    "model.add(layers.Lambda(lambda x: tf.reduce_mean(x,axis= 1)))\n",
    "model.add(layers.Dense(hidden_dimension, activation='relu'))\n",
    "model.add(layers.Dense(output_dimension,activation =\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 학습 모델 compile \n",
    "- optimizer : Adam \n",
    "- loss : 이진 교차 엔트로피 손실 함수 \n",
    "- 모델 성능 측정 : accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer =tf.keras.optimizers.Adam(0.001),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 모델 학습 하기 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# #시퀀스 패딩\n",
    "# padded_sequences = pad_sequences(sequences, padding='post')\n",
    "# sequences = np.array(padded_sequences)\n",
    "# labels = np.array(labels)\n",
    "# model.fit(sequences, labels, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "###\n",
    "변환모듈 \n",
    "- 파이프라인\n",
    "- 특징 추출\n",
    "- 데이터 전처리\n",
    "- 차원축소 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_dataset : dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "shape of data: (150, 4)\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n",
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__\n",
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "print(\"iris_dataset : {}\".format(iris_dataset.keys()))\n",
    "print(\"shape of data: {}\".format(iris_dataset['data'].shape))\n",
    "# print(iris_dataset['data'])\n",
    "print(iris_dataset['feature_names'])\n",
    "\n",
    "print(iris_dataset['target'])\n",
    "print(iris_dataset['target_names'])\n",
    "print(iris_dataset['DESCR'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 사이킷 런을 이용한 데이터 분리\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shaep of train_input : (112, 4)\n",
      "shaep of test_input : (38, 4)\n",
      "shaep of train_lb : (112,)\n",
      "shaep of test_lb : (38,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_label, test_label = \\\n",
    "    train_test_split(\n",
    "        iris_dataset['data'],\n",
    "        iris_dataset['target'],\n",
    "        test_size=0.25,\n",
    "        random_state=42\n",
    "        )\n",
    "print(f\"shaep of train_input : {train_input.shape}\")\n",
    "print(f\"shaep of test_input : {test_input.shape}\")\n",
    "print(f\"shaep of train_lb : {train_label.shape}\")\n",
    "print(f\"shaep of test_lb : {test_label.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### page 58 비지도학습 을 이용한 text 처리 기법 \n",
    "- CountVectorize:\n",
    "    * 각 텍스트에서 횟수를 기준으로 특징을 추출하는 방법 \n",
    "- TfidfVectorizer: \n",
    "    * TF-IDF 라는 값을 사용해 텍스트에서 특징을 추출 하는 방법 \n",
    "\n",
    "- HashingVectorizer:\n",
    "    * Count 와 같은 방식이나 텍스트를 처리할때 해시 함수를 사용해 시간을 줄임\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 3, '배가': 6, '고프다': 0, '내일': 4, '점심': 7, '뭐먹지': 5, '공부해야겠다': 1, '점심먹고': 8, '공부해야지': 2}\n",
      "['나는 배가 고프다']\n",
      "[[1 0 0 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text_data = ['나는 배가 고프다','내일 점심 뭐먹지','내일 공부해야겠다','점심먹고 공부해야지']\n",
    "count_vectorizer =CountVectorizer()\n",
    "count_vectorizer.fit(text_data)\n",
    "print(count_vectorizer.vocabulary_)\n",
    "sentence = [text_data[0]] ## \n",
    "print(sentence)\n",
    "print(count_vectorizer.transform(sentence).toarray())\n",
    "\n",
    "\n",
    "def countVectorize(text_data):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    count_vectorizer =CountVectorizer()\n",
    "    count_vectorizer.fit([text_data])\n",
    "    print(yellow(f\"vocab : \\n\"), red(count_vectorizer.vocabulary_))\n",
    "    print()\n",
    "    sentence =[[text_data][0]] ## \n",
    "    print(sentence)\n",
    "    print(yellow(f\"Vectorized Sentence :\\n\"),count_vectorizer.transform(sentence).toarray())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 신문기사 데이터에 적용해보자 . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mCountVectorize 함수로로 토큰화합니다. \u001b[0m\n",
      "\u001b[93mvocab : \n",
      "\u001b[0m \u001b[91m{'정책자금': 463, '상환연장': 281, '금융지원': 116, '3종': 18, '세트': 301, '추진5대': 519, '고정비용': 91, '지원': 489, '경영부담': 74, '매출': 205, '기반': 122, '확충': 583, '규제합리화': 111, '방안': 226, '추진': 518, '사회안전망': 272, '가입독려': 44, '소상공인': 308, '실효성': 330, '의문': 385, '장기적': 430, '대책': 166, '필요': 548, '서울': 291, '뉴시스': 156, '추상철': 517, '기자': 126, '3일': 17, '오후': 361, '서울의': 292, '전통시장에서': 446, '상인이': 278, '손님을': 315, '기다리고': 121, '있다': 421, '2024': 11, '06': 3, '03': 1, 'scchoo': 41, 'newsis': 38, 'com': 32, '세종': 299, '김동현': 134, '용윤신': 372, '임하은': 418, '정부가': 456, '올해': 362, '하반기부터': 552, '소상공인의': 313, '경영': 73, '애로를': 338, '해소하기': 567, '위해': 377, '금융지원과': 117, '배달료': 231, '임대료': 412, '전기료': 443, '5대': 26, '고정비용에': 92, '대한': 176, '부담을': 246, '낮추는': 140, '방안을': 228, '본격화한다': 242, '이번': 390, '대책은': 168, '코로나19': 525, '사태': 271, '이후': 403, '고금리': 85, '장기화로': 432, '채무가': 503, '누적되고': 155, '준비': 478, '부족으로': 249, '창업과': 502, '폐업을': 539, '반복하며': 218, '고통을': 93, '받고': 220, '있는': 420, '경영부담을': 75, '완화하는데': 365, '초점을': 509, '맞췄다': 204, '정부는': 457, '정부서울청사에서': 459, '최상목': 514, '경제부총리': 78, '기획재정부': 131, '장관': 429, '주재로': 476, '관계부처': 99, '합동브리핑을': 561, '열고': 354, '같은': 58, '내용의': 145, '역동경제': 345, '로드맵': 195, '하반기': 551, '경제정책방향': 81, '발표했다': 225, '완화': 363, '3종세트': 19, '부담완화': 245, '사회안정망': 273, '강화': 55, '크게': 526, '4가지': 22, '분야로': 251, '추진된다': 521, '발표한': 224, '2024년': 12, '따르면': 193, '폐업하는': 540, '소상공인에게': 311, '채무조정과': 506, '재취업을': 435, '원한다': 374, '새출발기금을': 286, '40조원': 21, '이상으로': 393, '확대하고': 576, '점포철거비': 453, '지원금을': 490, '최대': 513, '400만원으로': 20, '상향한다': 280, '그래픽': 112, '전진우': 445, '618tue': 30, 'com정책자금': 36, '추진금융지원은': 520, '분할상환': 256, '지원대상': 492, '확대': 575, '5년까지': 25, '기간연장': 118, '5조원': 27, '규모의': 109, '전환보증을': 449, '신설해': 324, '보증부': 241, '대출': 170, '만기': 198, '연장': 350, '저금리': 437, '대환대출': 179, '등으로': 190, '마련했다': 197, '상환연장은': 282, '대상을': 165, '사업경력': 264, '3년': 16, '이상': 391, '잔액': 428, '3000만원': 15, '이상에서': 392, '업력과': 342, '대출잔액': 174, '기준을': 130, '폐지하고': 541, '연장시': 351, '적용하는': 442, '금리를': 114, '기존': 127, '이용금리': 395, '포인트': 542, '적용': 441, '기간은': 119, '확대하기로': 577, '했다': 568, '지역신보': 488, '대출을': 172, '이용하는': 396, '소상공인이': 314, '상환을': 283, '연장하기': 353, '전환보증제도도': 450, '신설한다': 323, '소상공인은': 312, '중도상환수수료를': 480, '면제': 209, '받을': 221, '있고': 419, '저신용자는': 439, '산출보증료율에서': 274, 'p를': 40, '인하받는다': 407, '은행': 382, '비은행권의': 260, '대출로': 171, '대환하는': 181, '프로그램': 546, '참여': 500, '요건을': 370, '완화해': 366, '고정금리': 90, '5000만원': 23, '한도를': 557, '10년': 5, '분할': 255, '상환하도록': 284, '한다는': 556, '구상이다': 105, '이외에도': 394, '외식업계': 368, '농산물': 151, '구매자금': 104, '융자금': 381, '인하': 405, '저신용': 438, '대상': 163, '기준': 129, '상향': 279, '등을': 191, '통해': 529, '추가적인': 516, '정책': 461, '자금을': 425, '공급한다는': 95, '계획이다': 84, '정부': 455, '관계자는': 100, '세트는': 302, '채무걱정': 504, '덜어드림': 182, '세트라고': 303, '명명을': 211, '전환보증': 448, '대환대출이라는': 180, '가지': 48, '툴을': 532, '바탕으로': 217, '해서': 566, '갖고': 57, '대출의': 173, '만기를': 199, '연장하고': 352, '상환할': 285, '제도를': 466, '대폭': 175, '넣었다': 146, '설명했다': 294, '물건을': 214, '판매하고': 534, 'com5대': 33, '인건비': 404, '관리비': 102, '지원책도': 495, '내놨다': 143, '먼저': 208, '공정거래위원회': 97, '농축수산식품부': 152, '중소기업벤처부': 481, '정부부처와': 458, '배달앱': 236, '사업자': 265, '이해관계자': 400, '등이': 192, '참여해': 501, '경제적': 79, '부담': 244, '완화를': 364, '위한': 376, '논의를': 150, '실시하고': 329, '분야별': 252, '상생방안을': 277, '마련한다': 196, '플랫폼': 547, '자율': 427, '규제': 110, '기구': 120, '총괄위원회': 511, '역할을': 346, '강화해': 56, '이해관계자의': 401, '수요를': 317, '반영한': 219, '아젠다': 333, '설정': 295, '신속한': 325, '문제해결을': 213, '추진하고': 522, '최근': 512, '부담이': 247, '커지고': 524, '사업주': 267, '배달료는': 233, '영세': 356, '소상공인에': 310, '한해': 560, '배달료를': 234, '신규로': 322, '지원한다': 498, '임대료는': 413, '임차료를': 417, '인하한': 408, '임대인에': 415, '세제지원과': 298, '국유재산': 108, '사용료': 270, '감면': 51, '지원기간을': 491, '내년말까지': 141, '지자체와': 499, '협업해': 573, '공유재산': 96, '감면도': 52, '지속': 486, '추진한다는': 523, '방침이다': 229, '경감을': 72, '대상도': 164, '확대한다': 579, '현행': 572, '연매출': 349, '이하의': 399, '매출로': 206, '설정된': 296, '6000만원': 28, '이하로': 398, '늘려': 158, '50만명의': 24, '혜택을': 574, '준다는': 477, '절감을': 451, '위해선': 379, '키오스크': 527, '서빙로봇': 290, '자동화': 426, '스마트': 318, '기술보급': 124, '지원을': 494, '음식점업': 383, '주방보조원': 473, '비자': 261, '시범사업': 321, '평가를': 536, '토대로': 528, '지역': 487, '업력': 341, '요건': 369, '외국인': 367, '고용허가': 89, '범위를': 238, '확대하는': 578, '것을': 69, '검토키로': 66, '아울러': 332, '부과의': 243, '투명성을': 530, '확보하기': 582, '개정된': 64, '상가임대차': 276, '표준계약서를': 544, '적극': 440, '활용하도록': 584, '유도하고': 380, '운영과정에서': 373, '개선': 59, '필요사항을': 549, '검토할': 67, '예정이다': 360, '분쟁': 253, '발생시': 222, '임대차': 416, '분쟁조정위원회는': 254, '해결을': 565, '돕는다': 187, '위해서는': 378, '기술': 123, '보급': 240, '재정': 433, '확대할': 581, '예정': 359, '이라며': 388, '음식점업에': 384, '대해선': 178, '현재': 571, '한식업': 558, '7년': 31, '주방보조원에': 474, '한정해': 559, '허용되는': 570, '비자를': 262, '추가적으로': 515, '내용을': 144, '이라고': 387, '전했다': 447, '20일': 13, '시내': 319, '상가에': 275, '임대문의': 414, '게시물이': 70, '부착돼': 250, '폐업으로': 538, '인한': 409, '노란우산': 147, '공제금': 98, '지급액이': 484, '늘고': 157, '것으로': 68, '나타났다': 138, '05': 2, '20': 10, 'com규제합리화': 34, '가입독려소상공인의': 45, '영업환경': 357, '개선을': 60, '합리화': 562, '방안도': 227, '도입한다': 185, '금융접근성': 115, '기존에': 128, '사업주의': 268, '신용': 326, '또는': 194, '담보': 161, '중심으로': 482, '평가하던': 537, '신용평가체제를': 328, '매출액': 207, '사업장': 266, '정보': 454, '개편해': 65, '개인사업자의': 63, '자금': 424, '조달을': 468, '원활하게': 375, '돕는다는': 188, '개인사업자에': 62, '신용평가를': 327, '고도화하기': 86, '다양한': 160, '공공정보를': 94, '제공하기로': 464, '국세청의': 107, '소득세': 306, '표본자료에는': 543, '근로소득세': 113, '15개': 6, '항목': 563, '종합소득세': 472, '관련': 101, '18개': 7, '항목을': 564, '제공하는데': 465, '이를': 389, '확대한다는': 580, '소매상인의': 307, '비축물가': 263, '판매': 533, '허용': 569, '도로점용료': 183, '25': 14, '무료': 212, '법률지원': 239, '서비스': 289, '간이과세자': 50, '수수료': 316, '영업환경을': 358, '개선해': 61, '나간다는': 136, '두터운': 189, '생계안전망': 287, '구축을': 106, '노란우산공제': 148, '고용보험': 87, '가입을': 47, '독려한다': 186, '납입부금에': 139, '대해': 177, '소득공제': 305, '연간': 347, '600만원으로': 29, '조정하고': 470, '고용보험료': 88, '지원신청': 493, '절차를': 452, '간소화해': 49, '가입률을': 46, '높인다': 154, '김근수': 133, '1일': 8, '중구': 479, '명동': 210, '시내의': 320, '가게': 42, '앞에': 337, '임대': 411, '안내문이': 334, '붙어': 257, '07': 4, '01': 0, 'ks': 37, 'com전문가들': 35, '전문가들은': 444, '내놓은': 142, '대책에': 167, '어려움을': 339, '겪고': 71, '일시적인': 410, '도움을': 184, '있지만': 423, '실효성에': 331, '의문을': 386, '표하며': 545, '장기적인': 431, '대책을': 169, '만들어야': 201, '한다고': 555, '조언했다': 469, '김광석': 132, '한국경제산업연구원': 553, '연구실장은': 348, '재정을': 434, '투입하지': 531, '않고': 335, '배달료가': 232, '인하될': 406, '있을': 422, '배달플랫폼': 237, '기업드에게': 125, '배달비': 235, '감소를': 53, '요구한다면': 371, '다른': 159, '부분에서': 248, '비용감소분을': 259, '채우려고': 507, '노력할': 149, '가능성이': 43, '높다': 153, '말했다': 203, '이정희': 397, '중앙대': 483, '경제학과': 82, '교수는': 103, '당장': 162, '어렵다고': 340, '하니까': 550, '계속': 83, '책임질': 508, '없는': 343, '만큼': 202, '생계형과': 288, '사업형으로': 269, '나눈': 137, '제시해야': 467, '한다': 554, '석병훈': 293, '이화여대': 402, '성장을': 297, '촉진하기': 510, '지원책은': 496, '바람직하지만': 216, '소상공인들의': 309, '채무를': 505, '조정해주는': 471, '바람직하지': 215, '않다': 336, '경쟁력': 76, '소기업으로': 304, '만들고': 200, '경쟁력이': 77, '없으면': 344, '재취업할': 436, '지원하는': 497, '정책을': 462, '펼쳐야': 535, '주장했다': 475, '강종민': 54, '김병환': 135, '1차관이': 9, '지난': 485, '세종시': 300, '정부세종청사에서': 460, '열린': 355, '경제정책': 80, '방향': 230, '브리핑에서': 258, '발언하고': 223, 'ppkjm': 39}\u001b[0m\n",
      "\n",
      "['[\\n정책자금 상환연장 등 금융지원 3종 세트 추진5대 고정비용 지원…경영부담↓매출 기반 확충 규제합리화 방안 추진 및 사회안전망 가입독려\"소상공인 지원 실효성 의문…장기적 대책 필요\"\\n\\n\\n\\n[서울=뉴시스] 추상철 기자 = 3일 오후 서울의 한 전통시장에서 상인이 손님을 기다리고 있다. 2024.06.03. scchoo@newsis.com[세종=뉴시스]김동현 용윤신 임하은 기자 = 정부가 올해 하반기부터 소상공인의 경영 애로를 해소하기 위해 금융지원과 배달료·임대료·전기료 등 5대 고정비용에 대한 부담을 낮추는 방안을 본격화한다. 이번 대책은 코로나19 사태 이후 고금리 장기화로 채무가 누적되고 준비 부족으로 창업과 폐업을 반복하며 고통을 받고 있는 소상공인의 경영부담을 완화하는데 초점을 맞췄다. 정부는 3일 정부서울청사에서 최상목 경제부총리 겸 기획재정부 장관 주재로 관계부처 합동브리핑을 열고 이 같은 내용의 \\'역동경제 로드맵 및 하반기 경제정책방향\\'을 발표했다.소상공인 경영부담 완화 대책은 ▲금융지원 3종세트 ▲5대 고정비용 부담완화 ▲매출 지원 ▲사회안정망 강화 등 크게 4가지 분야로 추진된다.\\n\\n\\n\\n[서울=뉴시스] 3일 정부가 발표한 \\'2024년 하반기 경제정책방향\\'에 따르면 정부가 폐업하는 소상공인에게 채무조정과 재취업을 원한다. 새출발기금을 40조원 이상으로 확대하고, 점포철거비 지원금을 최대 400만원으로 상향한다. (그래픽=전진우 기자) 618tue@newsis.com정책자금 상환연장 등 금융지원 3종 세트 추진금융지원은 정책자금 분할상환 지원대상 확대 및 최대 5년까지 기간연장, 5조원 규모의 전환보증을 신설해 보증부 대출 만기 연장, 저금리 대환대출 지원대상 확대 등으로 마련했다. 정책자금 상환연장은 지원 대상을 사업경력 3년 이상, 대출 잔액 3000만원 이상에서 업력과 대출잔액 기준을 폐지하고 연장시 적용하는 금리를 기존 이용금리 +0.2% 포인트(p)로 적용, 기간은 최대 5년까지 확대하기로 했다. 정부는 지역신보 보증부 대출을 이용하는 소상공인이 대출 상환을 최대 5년까지 연장하기 위해  5조원 규모의 전환보증제도도 신설한다. 소상공인은 중도상환수수료를 면제 받을 수 있고 저신용자는 산출보증료율에서 0.2%p를 인하받는다. 또 은행·비은행권의 7% 이상 고금리 대출을 저금리 대출로 대환하는 프로그램 참여 요건을 완화해 4.5% 고정금리, 5000만원 한도를 10년 분할 상환하도록 한다는 구상이다. 이외에도 외식업계 농산물 구매자금 융자금 인하, 저신용 소상공인 정책자금 지원 대상 기준 상향 등을 통해 추가적인 정책 자금을 공급한다는 계획이다. 정부 관계자는 \"소상공인 금융지원 3종 세트는 \\'채무걱정 덜어드림\\' 3종 세트라고 명명을 했다\"며 \"정책자금 상환연장, 전환보증, 대환대출이라는 세 가지 툴을 바탕으로 해서 소상공인이 갖고 있는 대출의 만기를 연장하고 분할 상환할 수 있는 제도를 대폭 넣었다\"고 설명했다.\\n\\n\\n\\n[서울=뉴시스] 추상철 기자 = 3일 오후 서울의 한 전통시장에서 상인이 물건을 판매하고 있다. 2024.06.03. scchoo@newsis.com5대 고정비용 지원…경영부담↓매출 기반 확충 배달료·임대료·전기료·인건비·관리비 등 5대 고정비용에 대한 지원책도 내놨다. 먼저 공정거래위원회, 농축수산식품부, 중소기업벤처부 등 정부부처와 배달앱 사업자 외식업계 이해관계자 등이 참여해 경제적 부담 완화를 위한 논의를 실시하고 분야별 상생방안을 마련한다.또 플랫폼 자율 규제 기구 내 총괄위원회 역할을 강화해 이해관계자의 수요를 반영한 아젠다 설정 및 신속한 문제해결을 추진하고 최근 부담이 커지고 있는 사업주 부담 배달료는 영세 소상공인에 한해 배달료를 신규로 지원한다. 임대료는 소상공인에게 임차료를 인하한 임대인에 대한 세제지원과 국유재산 사용료 감면 지원기간을 내년말까지 연장하고 지자체와 협업해 공유재산 사용료 감면도 지속 추진한다는 방침이다. 영세 소상공인의 전기료 부담 경감을 위해 전기료 지원 대상도 확대한다. 정부는 현행 연매출 3000만원 이하의 매출로 설정된 기준을 6000만원 이하로 늘려 최대 50만명의 소상공인에게 전기료 지원 혜택을 준다는 계획이다. 인건비 절감을 위해선 키오스크, 서빙로봇 등 자동화 스마트 기술보급 지원을 확대하고 음식점업 주방보조원 E-9 비자 시범사업 평가를 토대로 지역·업력 요건 등 외국인 고용허가 범위를 확대하는 것을 검토키로 했다. 아울러 관리비 부과의 투명성을 확보하기 위해 개정된 상가임대차 표준계약서를 적극 활용하도록 유도하고 운영과정에서 개선 필요사항을 적극 검토할 예정이다. 분쟁 발생시 임대차 분쟁조정위원회는 소상공인의 분쟁 해결을 돕는다. 정부 관계자는 \"인건비 지원을 위해서는 키오스크 등 스마트 기술 보급 지원을 위한 재정 지원을 확대할 예정\"이라며 \"음식점업에 대해선 현재 한식업, 업력 5~7년, 주방보조원에 한정해 허용되는 E-9 비자를 추가적으로 범위를 확대하는 내용을 검토할 것\"이라고 전했다.\\n\\n\\n\\n[서울=뉴시스] 추상철 기자 = 20일 오후 서울 시내 상가에 임대문의 게시물이 부착돼 있다. 소상공인의 폐업으로 인한 \\'노란우산 공제금\\' 지급액이 크게 늘고 있는 것으로 나타났다. 2024.05.20. scchoo@newsis.com규제합리화 방안 추진 및 사회안전망 가입독려소상공인의 영업환경 개선을 위한 규제 합리화 방안도 도입한다. 소상공인의 금융접근성 개선을 위해선 기존에 사업주의 신용 또는 담보 중심으로 평가하던 신용평가체제를 매출액 등 사업장 정보 중심으로 개편해 개인사업자의 자금 조달을 원활하게 돕는다는 구상이다.또 개인사업자에 대한 신용평가를 고도화하기 위해 다양한 공공정보를 제공하기로 했다. 현재 국세청의 소득세 표본자료에는 근로소득세 15개 항목, 종합소득세 관련 정보 18개 항목을 제공하는데 이를 확대한다는 계획이다.  이외에도 ▲소매상인의 비축물가 판매 허용 ▲소상공인 대상 도로점용료 25% 감면 ▲무료 법률지원 서비스 대상 확대 ▲간이과세자 매출 기준 확대 및 수수료 감면 등을 통해 영업환경을 개선해 나간다는 방침이다. 두터운 생계안전망 구축을 위해선 노란우산공제, 고용보험 등 사회안전망 가입을 독려한다. 노란우산공제 납입부금에 대해 소득공제 한도를 연간 600만원으로 상향 조정하고 고용보험료 지원신청 절차를 간소화해 가입률을 높인다.\\n\\n\\n\\n[서울=뉴시스] 김근수 기자 = 1일 오후 서울 중구 명동 시내의 한 가게 앞에 임대 안내문이 붙어 있다. 2024.07.01. ks@newsis.com전문가들 \"소상공인 지원 실효성 의문…장기적 대책 필요\" 전문가들은 정부가 내놓은 소상공인 지원 대책에 대해 어려움을 겪고 있는 소상공인에게 일시적인 도움을 줄 수 있지만 실효성에 대해 의문을 표하며 장기적인 대책을 만들어야 한다고 조언했다.김광석 한국경제산업연구원 연구실장은 \"재정을 투입하지 않고 배달료가 인하될 수 있을 지 의문\"이라며 \"배달플랫폼 기업드에게 배달비 감소를 요구한다면 다른 부분에서 비용감소분을 채우려고 노력할 가능성이 높다\"고 말했다. 이정희 중앙대 경제학과 교수는 \"정부가 내놓은 소상공인 대책은 당장 어렵다고 하니까 도움을 줄 수 있는 일시적인 방안\"이라며 \"배달료를 정부가 계속 책임질 수 없는 만큼 생계형과 사업형으로 나눈 소상공인 대책을 제시해야 한다\"고 조언했다. 석병훈 이화여대 경제학과 교수는 \"소상공인의 성장을 촉진하기 위한 지원책은 바람직하지만 소상공인들의 채무를 조정해주는 지원책은 바람직하지 않다\"며 \"경쟁력 있는 소상공인은 소기업으로 만들고 경쟁력이 없으면 재취업할 수 있는 방안을 지원하는 정책을 펼쳐야 한다\"고 주장했다.\\n\\n\\n\\n[세종=뉴시스] 강종민 기자 = 김병환 기획재정부 1차관이 지난 1일 세종시 정부세종청사에서 열린 하반기 경제정책 방향 및 역동경제 로드맵 브리핑에서 발언하고 있다. 2024.07.03. ppkjm@newsis.com\\n]']\n",
      "\u001b[93mVectorized Sentence :\n",
      "\u001b[0m [[ 1  3  1  2  2  1  1  1  2  1  1  5  1  1  1  2  1  4  4  1  1  1  1  1\n",
      "   1  3  3  2  1  1  1  1  2  1  1  1  1  1  6  1  1  3  1  1  1  1  1  1\n",
      "   1  1  1  3  1  1  1  1  1  1  1  1  2  1  1  1  1  1  1  2  1  1  1  1\n",
      "   1  1  3  1  1  1  1  1  1  2  2  1  3  2  1  1  1  1  1  3  2  1  1  1\n",
      "   1  1  1  1  2  1  2  2  1  2  1  1  1  2  2  1  1  1  1  1  4  1  1  1\n",
      "   1  1  2  1  1  1  7  1  1  2  2  2  1  1  1  1  1  1  1  1  1  1  2  1\n",
      "   1  1  1  1  2  1  1  1  1  1  1  1  7  1  1  1  1  1  1  3  1  1  2  1\n",
      "   3  2  3  1  2  1  1  1  4  3  1  1  1  1  1  1  2  1  1  1  1  1  1  2\n",
      "   1  1  1  2  1  1  1  1  1  1  1  1  1  4  1  1  1  1  1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  1  3  1  2  2  1  2  1  1  2  1  1  1  2  1\n",
      "   1  2  1  1  3  1  1  1  1  1  1  1  1  2  1  2  1  1  1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  2  1  3  1  1  1  1  1  2  2  1  3  1  1  1  1  1  1\n",
      "   1  1  1  7  2  1  1  1  1  1  1  2  1  2  1  1  1  1  1  1  9  1  1  4\n",
      "   2  7  2  1  1  1  2  1  1  1  1  1  1  1  1  1  1  1  2  1  1  1  1  1\n",
      "   1  1  1  1  1  2  1  1  1  2  1  1  1  1  1  1  2  1  1  1  2  1  1  1\n",
      "   1  4  1  1  1  1  1  1  2  1  1  1  1  1  1  1  4  5  1  3  1  1  1  1\n",
      "   1  3  1  1  3  1  1  2  1  1  2  1  1  1  1  1  1  1  1  1  3  1  1  1\n",
      "   1  1  2  1  2  1  1  1  1  1  1  1  9  5  1  1  1  1  1  1  1  1  2  1\n",
      "   1  1  1  1  1  2  1  1  2  1  1  5  1  1  2  1  1  1  1  1  1  1  2  2\n",
      "   6  3  1  1  1  1  1  5  1  1  1  1  1  2  1  1  1  1  1  1  1  1  1  1\n",
      "   1  1  2  1  1  1  1  1  1 10  1  1  2  1  4  1  2  1  1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  5  1  1  1  3  2  1  1  1  1  1  1  1  2  2\n",
      "   1  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1  1  3\n",
      "   1  1  2  1  1  2  1  1  1  1  1  1  1  1  1  1  4  1  1  2  1  1  1  4\n",
      "   2  1  2  1  1  1  1  2  1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "news = pd.read_csv(\"./NewsData/경제_20240704_10시17분.csv\")\n",
    "# print(news.columns)\n",
    "test_article  = news.iloc[0]['content']\n",
    "# print(test_article)\n",
    "from Functions import NLP_Service as N\n",
    "N.countVectorize(test_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### TfidfVectorizer\n",
    "- TF ( Term Frequency )특정단어 하나가 데이터 안에서 등장하는 횟수\n",
    "- DF (Document Frequency): 문서 빈도값. 특ㅈ3ㅓㅇ단어가 여러데이터에 자주 등장하는지를 알려주는 지표\n",
    "- IDF (Inverse Document Frequency ) DF 의 역수 : 다른데이터에 등장하지않을수록 커짐. \n",
    "- TF-IDF : TF 와 IDF 를 곱한값. 해당문서에 자주 등장하집만 다른 문서에는 많이 없는 단어일수록 높은 값. \n",
    "- 조사, 지시대명사는 TF는 크지만 IDF 값은 작아지므로 counterVectorize 가 가진 문제점 해결\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 3, '배가': 6, '고프다': 0, '내일': 4, '점심': 7, '뭐먹지': 5, '공부해야겠다': 1, '점심먹고': 8, '공부해야지': 2}\n",
      "['나는 배가 고프다']\n",
      "[[0.57735027 0.         0.         0.57735027 0.         0.\n",
      "  0.57735027 0.         0.        ]]\n",
      "\u001b[94mTF-IDF 함수로로 토큰화합니다. \u001b[0m\n",
      "\u001b[93mvocab : \n",
      "\u001b[0m \u001b[91m{'정책자금': 463, '상환연장': 281, '금융지원': 116, '3종': 18, '세트': 301, '추진5대': 519, '고정비용': 91, '지원': 489, '경영부담': 74, '매출': 205, '기반': 122, '확충': 583, '규제합리화': 111, '방안': 226, '추진': 518, '사회안전망': 272, '가입독려': 44, '소상공인': 308, '실효성': 330, '의문': 385, '장기적': 430, '대책': 166, '필요': 548, '서울': 291, '뉴시스': 156, '추상철': 517, '기자': 126, '3일': 17, '오후': 361, '서울의': 292, '전통시장에서': 446, '상인이': 278, '손님을': 315, '기다리고': 121, '있다': 421, '2024': 11, '06': 3, '03': 1, 'scchoo': 41, 'newsis': 38, 'com': 32, '세종': 299, '김동현': 134, '용윤신': 372, '임하은': 418, '정부가': 456, '올해': 362, '하반기부터': 552, '소상공인의': 313, '경영': 73, '애로를': 338, '해소하기': 567, '위해': 377, '금융지원과': 117, '배달료': 231, '임대료': 412, '전기료': 443, '5대': 26, '고정비용에': 92, '대한': 176, '부담을': 246, '낮추는': 140, '방안을': 228, '본격화한다': 242, '이번': 390, '대책은': 168, '코로나19': 525, '사태': 271, '이후': 403, '고금리': 85, '장기화로': 432, '채무가': 503, '누적되고': 155, '준비': 478, '부족으로': 249, '창업과': 502, '폐업을': 539, '반복하며': 218, '고통을': 93, '받고': 220, '있는': 420, '경영부담을': 75, '완화하는데': 365, '초점을': 509, '맞췄다': 204, '정부는': 457, '정부서울청사에서': 459, '최상목': 514, '경제부총리': 78, '기획재정부': 131, '장관': 429, '주재로': 476, '관계부처': 99, '합동브리핑을': 561, '열고': 354, '같은': 58, '내용의': 145, '역동경제': 345, '로드맵': 195, '하반기': 551, '경제정책방향': 81, '발표했다': 225, '완화': 363, '3종세트': 19, '부담완화': 245, '사회안정망': 273, '강화': 55, '크게': 526, '4가지': 22, '분야로': 251, '추진된다': 521, '발표한': 224, '2024년': 12, '따르면': 193, '폐업하는': 540, '소상공인에게': 311, '채무조정과': 506, '재취업을': 435, '원한다': 374, '새출발기금을': 286, '40조원': 21, '이상으로': 393, '확대하고': 576, '점포철거비': 453, '지원금을': 490, '최대': 513, '400만원으로': 20, '상향한다': 280, '그래픽': 112, '전진우': 445, '618tue': 30, 'com정책자금': 36, '추진금융지원은': 520, '분할상환': 256, '지원대상': 492, '확대': 575, '5년까지': 25, '기간연장': 118, '5조원': 27, '규모의': 109, '전환보증을': 449, '신설해': 324, '보증부': 241, '대출': 170, '만기': 198, '연장': 350, '저금리': 437, '대환대출': 179, '등으로': 190, '마련했다': 197, '상환연장은': 282, '대상을': 165, '사업경력': 264, '3년': 16, '이상': 391, '잔액': 428, '3000만원': 15, '이상에서': 392, '업력과': 342, '대출잔액': 174, '기준을': 130, '폐지하고': 541, '연장시': 351, '적용하는': 442, '금리를': 114, '기존': 127, '이용금리': 395, '포인트': 542, '적용': 441, '기간은': 119, '확대하기로': 577, '했다': 568, '지역신보': 488, '대출을': 172, '이용하는': 396, '소상공인이': 314, '상환을': 283, '연장하기': 353, '전환보증제도도': 450, '신설한다': 323, '소상공인은': 312, '중도상환수수료를': 480, '면제': 209, '받을': 221, '있고': 419, '저신용자는': 439, '산출보증료율에서': 274, 'p를': 40, '인하받는다': 407, '은행': 382, '비은행권의': 260, '대출로': 171, '대환하는': 181, '프로그램': 546, '참여': 500, '요건을': 370, '완화해': 366, '고정금리': 90, '5000만원': 23, '한도를': 557, '10년': 5, '분할': 255, '상환하도록': 284, '한다는': 556, '구상이다': 105, '이외에도': 394, '외식업계': 368, '농산물': 151, '구매자금': 104, '융자금': 381, '인하': 405, '저신용': 438, '대상': 163, '기준': 129, '상향': 279, '등을': 191, '통해': 529, '추가적인': 516, '정책': 461, '자금을': 425, '공급한다는': 95, '계획이다': 84, '정부': 455, '관계자는': 100, '세트는': 302, '채무걱정': 504, '덜어드림': 182, '세트라고': 303, '명명을': 211, '전환보증': 448, '대환대출이라는': 180, '가지': 48, '툴을': 532, '바탕으로': 217, '해서': 566, '갖고': 57, '대출의': 173, '만기를': 199, '연장하고': 352, '상환할': 285, '제도를': 466, '대폭': 175, '넣었다': 146, '설명했다': 294, '물건을': 214, '판매하고': 534, 'com5대': 33, '인건비': 404, '관리비': 102, '지원책도': 495, '내놨다': 143, '먼저': 208, '공정거래위원회': 97, '농축수산식품부': 152, '중소기업벤처부': 481, '정부부처와': 458, '배달앱': 236, '사업자': 265, '이해관계자': 400, '등이': 192, '참여해': 501, '경제적': 79, '부담': 244, '완화를': 364, '위한': 376, '논의를': 150, '실시하고': 329, '분야별': 252, '상생방안을': 277, '마련한다': 196, '플랫폼': 547, '자율': 427, '규제': 110, '기구': 120, '총괄위원회': 511, '역할을': 346, '강화해': 56, '이해관계자의': 401, '수요를': 317, '반영한': 219, '아젠다': 333, '설정': 295, '신속한': 325, '문제해결을': 213, '추진하고': 522, '최근': 512, '부담이': 247, '커지고': 524, '사업주': 267, '배달료는': 233, '영세': 356, '소상공인에': 310, '한해': 560, '배달료를': 234, '신규로': 322, '지원한다': 498, '임대료는': 413, '임차료를': 417, '인하한': 408, '임대인에': 415, '세제지원과': 298, '국유재산': 108, '사용료': 270, '감면': 51, '지원기간을': 491, '내년말까지': 141, '지자체와': 499, '협업해': 573, '공유재산': 96, '감면도': 52, '지속': 486, '추진한다는': 523, '방침이다': 229, '경감을': 72, '대상도': 164, '확대한다': 579, '현행': 572, '연매출': 349, '이하의': 399, '매출로': 206, '설정된': 296, '6000만원': 28, '이하로': 398, '늘려': 158, '50만명의': 24, '혜택을': 574, '준다는': 477, '절감을': 451, '위해선': 379, '키오스크': 527, '서빙로봇': 290, '자동화': 426, '스마트': 318, '기술보급': 124, '지원을': 494, '음식점업': 383, '주방보조원': 473, '비자': 261, '시범사업': 321, '평가를': 536, '토대로': 528, '지역': 487, '업력': 341, '요건': 369, '외국인': 367, '고용허가': 89, '범위를': 238, '확대하는': 578, '것을': 69, '검토키로': 66, '아울러': 332, '부과의': 243, '투명성을': 530, '확보하기': 582, '개정된': 64, '상가임대차': 276, '표준계약서를': 544, '적극': 440, '활용하도록': 584, '유도하고': 380, '운영과정에서': 373, '개선': 59, '필요사항을': 549, '검토할': 67, '예정이다': 360, '분쟁': 253, '발생시': 222, '임대차': 416, '분쟁조정위원회는': 254, '해결을': 565, '돕는다': 187, '위해서는': 378, '기술': 123, '보급': 240, '재정': 433, '확대할': 581, '예정': 359, '이라며': 388, '음식점업에': 384, '대해선': 178, '현재': 571, '한식업': 558, '7년': 31, '주방보조원에': 474, '한정해': 559, '허용되는': 570, '비자를': 262, '추가적으로': 515, '내용을': 144, '이라고': 387, '전했다': 447, '20일': 13, '시내': 319, '상가에': 275, '임대문의': 414, '게시물이': 70, '부착돼': 250, '폐업으로': 538, '인한': 409, '노란우산': 147, '공제금': 98, '지급액이': 484, '늘고': 157, '것으로': 68, '나타났다': 138, '05': 2, '20': 10, 'com규제합리화': 34, '가입독려소상공인의': 45, '영업환경': 357, '개선을': 60, '합리화': 562, '방안도': 227, '도입한다': 185, '금융접근성': 115, '기존에': 128, '사업주의': 268, '신용': 326, '또는': 194, '담보': 161, '중심으로': 482, '평가하던': 537, '신용평가체제를': 328, '매출액': 207, '사업장': 266, '정보': 454, '개편해': 65, '개인사업자의': 63, '자금': 424, '조달을': 468, '원활하게': 375, '돕는다는': 188, '개인사업자에': 62, '신용평가를': 327, '고도화하기': 86, '다양한': 160, '공공정보를': 94, '제공하기로': 464, '국세청의': 107, '소득세': 306, '표본자료에는': 543, '근로소득세': 113, '15개': 6, '항목': 563, '종합소득세': 472, '관련': 101, '18개': 7, '항목을': 564, '제공하는데': 465, '이를': 389, '확대한다는': 580, '소매상인의': 307, '비축물가': 263, '판매': 533, '허용': 569, '도로점용료': 183, '25': 14, '무료': 212, '법률지원': 239, '서비스': 289, '간이과세자': 50, '수수료': 316, '영업환경을': 358, '개선해': 61, '나간다는': 136, '두터운': 189, '생계안전망': 287, '구축을': 106, '노란우산공제': 148, '고용보험': 87, '가입을': 47, '독려한다': 186, '납입부금에': 139, '대해': 177, '소득공제': 305, '연간': 347, '600만원으로': 29, '조정하고': 470, '고용보험료': 88, '지원신청': 493, '절차를': 452, '간소화해': 49, '가입률을': 46, '높인다': 154, '김근수': 133, '1일': 8, '중구': 479, '명동': 210, '시내의': 320, '가게': 42, '앞에': 337, '임대': 411, '안내문이': 334, '붙어': 257, '07': 4, '01': 0, 'ks': 37, 'com전문가들': 35, '전문가들은': 444, '내놓은': 142, '대책에': 167, '어려움을': 339, '겪고': 71, '일시적인': 410, '도움을': 184, '있지만': 423, '실효성에': 331, '의문을': 386, '표하며': 545, '장기적인': 431, '대책을': 169, '만들어야': 201, '한다고': 555, '조언했다': 469, '김광석': 132, '한국경제산업연구원': 553, '연구실장은': 348, '재정을': 434, '투입하지': 531, '않고': 335, '배달료가': 232, '인하될': 406, '있을': 422, '배달플랫폼': 237, '기업드에게': 125, '배달비': 235, '감소를': 53, '요구한다면': 371, '다른': 159, '부분에서': 248, '비용감소분을': 259, '채우려고': 507, '노력할': 149, '가능성이': 43, '높다': 153, '말했다': 203, '이정희': 397, '중앙대': 483, '경제학과': 82, '교수는': 103, '당장': 162, '어렵다고': 340, '하니까': 550, '계속': 83, '책임질': 508, '없는': 343, '만큼': 202, '생계형과': 288, '사업형으로': 269, '나눈': 137, '제시해야': 467, '한다': 554, '석병훈': 293, '이화여대': 402, '성장을': 297, '촉진하기': 510, '지원책은': 496, '바람직하지만': 216, '소상공인들의': 309, '채무를': 505, '조정해주는': 471, '바람직하지': 215, '않다': 336, '경쟁력': 76, '소기업으로': 304, '만들고': 200, '경쟁력이': 77, '없으면': 344, '재취업할': 436, '지원하는': 497, '정책을': 462, '펼쳐야': 535, '주장했다': 475, '강종민': 54, '김병환': 135, '1차관이': 9, '지난': 485, '세종시': 300, '정부세종청사에서': 460, '열린': 355, '경제정책': 80, '방향': 230, '브리핑에서': 258, '발언하고': 223, 'ppkjm': 39}\u001b[0m\n",
      "['[\\n정책자금 상환연장 등 금융지원 3종 세트 추진5대 고정비용 지원…경영부담↓매출 기반 확충 규제합리화 방안 추진 및 사회안전망 가입독려\"소상공인 지원 실효성 의문…장기적 대책 필요\"\\n\\n\\n\\n[서울=뉴시스] 추상철 기자 = 3일 오후 서울의 한 전통시장에서 상인이 손님을 기다리고 있다. 2024.06.03. scchoo@newsis.com[세종=뉴시스]김동현 용윤신 임하은 기자 = 정부가 올해 하반기부터 소상공인의 경영 애로를 해소하기 위해 금융지원과 배달료·임대료·전기료 등 5대 고정비용에 대한 부담을 낮추는 방안을 본격화한다. 이번 대책은 코로나19 사태 이후 고금리 장기화로 채무가 누적되고 준비 부족으로 창업과 폐업을 반복하며 고통을 받고 있는 소상공인의 경영부담을 완화하는데 초점을 맞췄다. 정부는 3일 정부서울청사에서 최상목 경제부총리 겸 기획재정부 장관 주재로 관계부처 합동브리핑을 열고 이 같은 내용의 \\'역동경제 로드맵 및 하반기 경제정책방향\\'을 발표했다.소상공인 경영부담 완화 대책은 ▲금융지원 3종세트 ▲5대 고정비용 부담완화 ▲매출 지원 ▲사회안정망 강화 등 크게 4가지 분야로 추진된다.\\n\\n\\n\\n[서울=뉴시스] 3일 정부가 발표한 \\'2024년 하반기 경제정책방향\\'에 따르면 정부가 폐업하는 소상공인에게 채무조정과 재취업을 원한다. 새출발기금을 40조원 이상으로 확대하고, 점포철거비 지원금을 최대 400만원으로 상향한다. (그래픽=전진우 기자) 618tue@newsis.com정책자금 상환연장 등 금융지원 3종 세트 추진금융지원은 정책자금 분할상환 지원대상 확대 및 최대 5년까지 기간연장, 5조원 규모의 전환보증을 신설해 보증부 대출 만기 연장, 저금리 대환대출 지원대상 확대 등으로 마련했다. 정책자금 상환연장은 지원 대상을 사업경력 3년 이상, 대출 잔액 3000만원 이상에서 업력과 대출잔액 기준을 폐지하고 연장시 적용하는 금리를 기존 이용금리 +0.2% 포인트(p)로 적용, 기간은 최대 5년까지 확대하기로 했다. 정부는 지역신보 보증부 대출을 이용하는 소상공인이 대출 상환을 최대 5년까지 연장하기 위해  5조원 규모의 전환보증제도도 신설한다. 소상공인은 중도상환수수료를 면제 받을 수 있고 저신용자는 산출보증료율에서 0.2%p를 인하받는다. 또 은행·비은행권의 7% 이상 고금리 대출을 저금리 대출로 대환하는 프로그램 참여 요건을 완화해 4.5% 고정금리, 5000만원 한도를 10년 분할 상환하도록 한다는 구상이다. 이외에도 외식업계 농산물 구매자금 융자금 인하, 저신용 소상공인 정책자금 지원 대상 기준 상향 등을 통해 추가적인 정책 자금을 공급한다는 계획이다. 정부 관계자는 \"소상공인 금융지원 3종 세트는 \\'채무걱정 덜어드림\\' 3종 세트라고 명명을 했다\"며 \"정책자금 상환연장, 전환보증, 대환대출이라는 세 가지 툴을 바탕으로 해서 소상공인이 갖고 있는 대출의 만기를 연장하고 분할 상환할 수 있는 제도를 대폭 넣었다\"고 설명했다.\\n\\n\\n\\n[서울=뉴시스] 추상철 기자 = 3일 오후 서울의 한 전통시장에서 상인이 물건을 판매하고 있다. 2024.06.03. scchoo@newsis.com5대 고정비용 지원…경영부담↓매출 기반 확충 배달료·임대료·전기료·인건비·관리비 등 5대 고정비용에 대한 지원책도 내놨다. 먼저 공정거래위원회, 농축수산식품부, 중소기업벤처부 등 정부부처와 배달앱 사업자 외식업계 이해관계자 등이 참여해 경제적 부담 완화를 위한 논의를 실시하고 분야별 상생방안을 마련한다.또 플랫폼 자율 규제 기구 내 총괄위원회 역할을 강화해 이해관계자의 수요를 반영한 아젠다 설정 및 신속한 문제해결을 추진하고 최근 부담이 커지고 있는 사업주 부담 배달료는 영세 소상공인에 한해 배달료를 신규로 지원한다. 임대료는 소상공인에게 임차료를 인하한 임대인에 대한 세제지원과 국유재산 사용료 감면 지원기간을 내년말까지 연장하고 지자체와 협업해 공유재산 사용료 감면도 지속 추진한다는 방침이다. 영세 소상공인의 전기료 부담 경감을 위해 전기료 지원 대상도 확대한다. 정부는 현행 연매출 3000만원 이하의 매출로 설정된 기준을 6000만원 이하로 늘려 최대 50만명의 소상공인에게 전기료 지원 혜택을 준다는 계획이다. 인건비 절감을 위해선 키오스크, 서빙로봇 등 자동화 스마트 기술보급 지원을 확대하고 음식점업 주방보조원 E-9 비자 시범사업 평가를 토대로 지역·업력 요건 등 외국인 고용허가 범위를 확대하는 것을 검토키로 했다. 아울러 관리비 부과의 투명성을 확보하기 위해 개정된 상가임대차 표준계약서를 적극 활용하도록 유도하고 운영과정에서 개선 필요사항을 적극 검토할 예정이다. 분쟁 발생시 임대차 분쟁조정위원회는 소상공인의 분쟁 해결을 돕는다. 정부 관계자는 \"인건비 지원을 위해서는 키오스크 등 스마트 기술 보급 지원을 위한 재정 지원을 확대할 예정\"이라며 \"음식점업에 대해선 현재 한식업, 업력 5~7년, 주방보조원에 한정해 허용되는 E-9 비자를 추가적으로 범위를 확대하는 내용을 검토할 것\"이라고 전했다.\\n\\n\\n\\n[서울=뉴시스] 추상철 기자 = 20일 오후 서울 시내 상가에 임대문의 게시물이 부착돼 있다. 소상공인의 폐업으로 인한 \\'노란우산 공제금\\' 지급액이 크게 늘고 있는 것으로 나타났다. 2024.05.20. scchoo@newsis.com규제합리화 방안 추진 및 사회안전망 가입독려소상공인의 영업환경 개선을 위한 규제 합리화 방안도 도입한다. 소상공인의 금융접근성 개선을 위해선 기존에 사업주의 신용 또는 담보 중심으로 평가하던 신용평가체제를 매출액 등 사업장 정보 중심으로 개편해 개인사업자의 자금 조달을 원활하게 돕는다는 구상이다.또 개인사업자에 대한 신용평가를 고도화하기 위해 다양한 공공정보를 제공하기로 했다. 현재 국세청의 소득세 표본자료에는 근로소득세 15개 항목, 종합소득세 관련 정보 18개 항목을 제공하는데 이를 확대한다는 계획이다.  이외에도 ▲소매상인의 비축물가 판매 허용 ▲소상공인 대상 도로점용료 25% 감면 ▲무료 법률지원 서비스 대상 확대 ▲간이과세자 매출 기준 확대 및 수수료 감면 등을 통해 영업환경을 개선해 나간다는 방침이다. 두터운 생계안전망 구축을 위해선 노란우산공제, 고용보험 등 사회안전망 가입을 독려한다. 노란우산공제 납입부금에 대해 소득공제 한도를 연간 600만원으로 상향 조정하고 고용보험료 지원신청 절차를 간소화해 가입률을 높인다.\\n\\n\\n\\n[서울=뉴시스] 김근수 기자 = 1일 오후 서울 중구 명동 시내의 한 가게 앞에 임대 안내문이 붙어 있다. 2024.07.01. ks@newsis.com전문가들 \"소상공인 지원 실효성 의문…장기적 대책 필요\" 전문가들은 정부가 내놓은 소상공인 지원 대책에 대해 어려움을 겪고 있는 소상공인에게 일시적인 도움을 줄 수 있지만 실효성에 대해 의문을 표하며 장기적인 대책을 만들어야 한다고 조언했다.김광석 한국경제산업연구원 연구실장은 \"재정을 투입하지 않고 배달료가 인하될 수 있을 지 의문\"이라며 \"배달플랫폼 기업드에게 배달비 감소를 요구한다면 다른 부분에서 비용감소분을 채우려고 노력할 가능성이 높다\"고 말했다. 이정희 중앙대 경제학과 교수는 \"정부가 내놓은 소상공인 대책은 당장 어렵다고 하니까 도움을 줄 수 있는 일시적인 방안\"이라며 \"배달료를 정부가 계속 책임질 수 없는 만큼 생계형과 사업형으로 나눈 소상공인 대책을 제시해야 한다\"고 조언했다. 석병훈 이화여대 경제학과 교수는 \"소상공인의 성장을 촉진하기 위한 지원책은 바람직하지만 소상공인들의 채무를 조정해주는 지원책은 바람직하지 않다\"며 \"경쟁력 있는 소상공인은 소기업으로 만들고 경쟁력이 없으면 재취업할 수 있는 방안을 지원하는 정책을 펼쳐야 한다\"고 주장했다.\\n\\n\\n\\n[세종=뉴시스] 강종민 기자 = 김병환 기획재정부 1차관이 지난 1일 세종시 정부세종청사에서 열린 하반기 경제정책 방향 및 역동경제 로드맵 브리핑에서 발언하고 있다. 2024.07.03. ppkjm@newsis.com\\n]']\n",
      "\u001b[93mVectorized Sentence :\n",
      "\u001b[0m [[0.02335709 0.07007128 0.02335709 0.04671418 0.04671418 0.02335709\n",
      "  0.02335709 0.02335709 0.04671418 0.02335709 0.02335709 0.11678546\n",
      "  0.02335709 0.02335709 0.02335709 0.04671418 0.02335709 0.09342837\n",
      "  0.09342837 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.07007128 0.07007128 0.04671418 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.04671418 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.14014255 0.02335709 0.02335709 0.07007128\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.07007128 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.04671418 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.04671418 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.07007128 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.04671418 0.04671418 0.02335709\n",
      "  0.07007128 0.04671418 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.07007128 0.04671418 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.04671418 0.02335709\n",
      "  0.04671418 0.04671418 0.02335709 0.04671418 0.02335709 0.02335709\n",
      "  0.02335709 0.04671418 0.04671418 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.09342837 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.04671418 0.02335709 0.02335709 0.02335709\n",
      "  0.16349964 0.02335709 0.02335709 0.04671418 0.04671418 0.04671418\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.04671418 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.04671418 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.16349964 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.07007128 0.02335709 0.02335709 0.04671418 0.02335709\n",
      "  0.07007128 0.04671418 0.07007128 0.02335709 0.04671418 0.02335709\n",
      "  0.02335709 0.02335709 0.09342837 0.07007128 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.04671418 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.04671418\n",
      "  0.02335709 0.02335709 0.02335709 0.04671418 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.09342837 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.07007128 0.02335709\n",
      "  0.04671418 0.04671418 0.02335709 0.04671418 0.02335709 0.02335709\n",
      "  0.04671418 0.02335709 0.02335709 0.02335709 0.04671418 0.02335709\n",
      "  0.02335709 0.04671418 0.02335709 0.02335709 0.07007128 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.04671418 0.02335709 0.04671418 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.04671418 0.02335709 0.07007128 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.04671418 0.04671418 0.02335709 0.07007128\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.16349964 0.04671418 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.04671418\n",
      "  0.02335709 0.04671418 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.21021383 0.02335709 0.02335709 0.09342837\n",
      "  0.04671418 0.16349964 0.04671418 0.02335709 0.02335709 0.02335709\n",
      "  0.04671418 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.04671418 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.04671418\n",
      "  0.02335709 0.02335709 0.02335709 0.04671418 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.04671418 0.02335709\n",
      "  0.02335709 0.02335709 0.04671418 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.09342837 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.04671418 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.09342837 0.11678546\n",
      "  0.02335709 0.07007128 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.07007128 0.02335709 0.02335709 0.07007128 0.02335709\n",
      "  0.02335709 0.04671418 0.02335709 0.02335709 0.04671418 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.07007128 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.04671418 0.02335709 0.04671418 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.21021383 0.11678546 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.04671418 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.04671418\n",
      "  0.02335709 0.02335709 0.04671418 0.02335709 0.02335709 0.11678546\n",
      "  0.02335709 0.02335709 0.04671418 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.04671418 0.04671418\n",
      "  0.14014255 0.07007128 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.11678546 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.04671418 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.04671418 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.23357092 0.02335709 0.02335709\n",
      "  0.04671418 0.02335709 0.09342837 0.02335709 0.04671418 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.11678546 0.02335709 0.02335709\n",
      "  0.02335709 0.07007128 0.04671418 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.04671418 0.04671418\n",
      "  0.02335709 0.04671418 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.04671418 0.02335709 0.02335709 0.07007128\n",
      "  0.02335709 0.02335709 0.04671418 0.02335709 0.02335709 0.04671418\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.02335709 0.02335709 0.02335709 0.09342837 0.02335709\n",
      "  0.02335709 0.04671418 0.02335709 0.02335709 0.02335709 0.09342837\n",
      "  0.04671418 0.02335709 0.04671418 0.02335709 0.02335709 0.02335709\n",
      "  0.02335709 0.04671418 0.02335709]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "text_data = ['나는 배가 고프다','내일 점심 뭐먹지','내일 공부해야겠다','점심먹고 공부해야지']\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(text_data)\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "sentence = [text_data[0]] ## \n",
    "print(sentence)\n",
    "print(tfidf_vectorizer.transform(sentence).toarray())\n",
    "\n",
    "\n",
    "\n",
    "def tfidfVectorize(text_data):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    tfidf_vectorizer =TfidfVectorizer()\n",
    "    tfidf_vectorizer.fit([text_data])\n",
    "    print(yellow(f\"vocab : \\n\"), red(tfidf_vectorizer.vocabulary_))\n",
    "\n",
    "    sentence =[[text_data][0]] ## \n",
    "    print(sentence)\n",
    "    print(yellow(f\"Vectorized Sentence :\\n\"),tfidf_vectorizer.transform(sentence).toarray())\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "news = pd.read_csv(\"./NewsData/경제_20240704_10시17분.csv\")\n",
    "# print(news.columns)\n",
    "test_article  = news.iloc[0]['content']\n",
    "# print(test_article)\n",
    "from Functions import NLP_Service as N\n",
    "N.tfidfVectorize(test_article)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 자연어 Tokenizing 도구 들 \n",
    "- 영어 토크나이징 라이브러리 :\n",
    "    *NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download() ## all 말뭉치 50개 다운로드 받음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'language', 'processing', '(', 'nlp', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'imformation', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data']\n"
     ]
    }
   ],
   "source": [
    "## 단어 단위 토크나이징\n",
    "from nltk.tokenize import word_tokenize\n",
    "sentence = '''natural language processing(nlp) is a subfield of computer science,\n",
    "imformation engineering, and artificial intelligence concerned with the interactions\n",
    "between computers and human  (natural) languages, in particular how to program computers\n",
    "to process and analyze large amounts of natural language data \n",
    "'''\n",
    "print(word_tokenize(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장단위 토크나이징 \n",
    "from nltk.tokenize import sent_tokenize\n",
    "paragraph = \"\"\" Natural language processing(nlp) is a subfield of computerscience,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
